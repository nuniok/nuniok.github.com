<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)">
<meta name="generator" content="Hexo 7.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/resource/img/fav2024.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/resource/img/fav2024.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/resource/img/fav2024.png">
  <link rel="mask-icon" href="/resource/img/fav2024.png" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"noge.top","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.8.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2929408904388376" crossorigin="anonymous"></script><meta property="og:type" content="website">
<meta property="og:title" content="码力欧">
<meta property="og:url" content="https://noge.top/page/7/index.html">
<meta property="og:site_name" content="码力欧">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="nuniok">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://noge.top/page/7/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/7/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>码力欧</title>
  

  <script src="/js/third-party/analytics/baidu-analytics.js"></script>
  <script async src="https://hm.baidu.com/hm.js?9cdc9a11cbd242c6336b07c464d8820c"></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">码力欧</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">瞎折腾</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a></li>
        <li class="menu-item menu-item-future"><a href="/future/" rel="section"><i class="sitemap fa-fw"></i>├ 动态</a></li>
        <li class="menu-item menu-item-nas"><a href="/nas/" rel="section"><i class="sitemap fa-fw"></i>├ NAS</a></li>
        <li class="menu-item menu-item-life"><a href="/life/" rel="section"><i class="sitemap fa-fw"></i>├ 生活</a></li>
        <li class="menu-item menu-item-career"><a href="/career/" rel="section"><i class="sitemap fa-fw"></i>└ 技术</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">nuniok</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">101</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">86</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/nuniok" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;nuniok" rel="noopener" target="_blank"><i class="github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:nuniok@163.com" title="E-Mail → mailto:nuniok@163.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i></a>
      </span>
  </div>



        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/09/28/2.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/09/28/2.html" class="post-title-link" itemprop="url">深度学习系列第四篇 — 神经反向传播</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-09-28 00:00:00" itemprop="dateCreated datePublished" datetime="2017-09-28T00:00:00+00:00">2017-09-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95">反向传播算法 - 维基百科</a></p>
<p>反向传播是一种与最优化方法结合使用的，用来训练人工神经网络的常用方法。通过计算所有权值的损失函数梯度，反馈给最优化方法，用来更新权值以最小化损失函数。</p>
<p>反向传播算法分成两个阶段：激励传播和权值更新</p>
<ul>
<li>激励传播：将输入值送入网络，活的激励响应，验证结果求差，从而获得响应误差。</li>
<li>权重更新：将输入的激励和响应误差相乘，获得权重的梯度，将梯度乘一个比例后取反加到权重上。</li>
</ul>
<p>训练的过程就是不断的重复这两个阶段，直到获得满意的预测准确率。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/09/25/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/09/25/1.html" class="post-title-link" itemprop="url">深度学习系列第二篇 — 深度神经网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-09-25 00:00:00" itemprop="dateCreated datePublished" datetime="2017-09-25T00:00:00+00:00">2017-09-25</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>上一节学习的向前传播算法是一种线性模型，全连接神经网络和单层神经网络模型都只能处理线性问题，这具有相当大的局限性。而深度学习要强调的是非线性。</p>
<h3 id="激活函数去线性化"><a href="#激活函数去线性化" class="headerlink" title="激活函数去线性化"></a>激活函数去线性化</h3><p>如下图，如果我们将每一个神经元的输出通过一个非线性函数，那么这个神经网络模型就不再是线性的了，而这个非线性函数就是激活函数，也实现了我们对神经元的去线性化。</p>
<p><img src="/resource/img/deep_learning/jihuohanshu.jpg" alt="激活函数去线性化"></p>
<p>下面列举了三个常用激活函数</p>
<ul>
<li>ReLU 函数</li>
<li>sigmoid 函数</li>
<li>tanh 函数</li>
</ul>
<p><img src="/resource/img/deep_learning/jihuohanshu2.jpg" alt="激活函数去线性化"></p>
<p>tf 中也提供了这几种不同的非线性激活函数。</p>
<p><code>tf.nn.relu(tf.matmul(x, w1) + biases1)</code></p>
<p>通过对 x 的加权增加偏置项，再在外层加上激活函数，实现神经元的非线性化。</p>
<h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>损失函数用来衡量预测值与真实值之间的不一致程度，是一个非负实值函数，损失函数越小，证明模型预测的越准确。</p>
<p>交叉熵可以用来衡量两个概率分布之间的距离，是分类问题中使用比较光的一种损失函数。对于两个概率分布 p 和 q，表示交叉熵如下：</p>
<p>$$H(p,q)&#x3D;-\sum_{x}p(x)log q(x)$$</p>
<p>将神经网络向前传播得到的结果变成概率分布使用 Softmax 回归，它可以作为一个算法来优化分类结果。假设神经网络的输出值为 <code>y1,y2,...yn</code>，那么 Softmax 回归处理的输出为：</p>
<p>$$softmax(y)<em>i&#x3D;y_i’&#x3D;\frac{e^{yi}}{\sum</em>{j&#x3D;1}^ne^{yj}}$$</p>
<p>如下图通过 Softmax 层将神经网络的输出变成一个概率分布。</p>
<p><img src="/resource/img/deep_learning/softmax.jpg" alt="Softmax"></p>
<p>交叉熵一般会与 Softmax 回归一起使用，tf 对这两个功能提供了封装提供函数 <code>tf.nn.softmax_cross_entropy_with_logits</code>。</p>
<p>对于回归问题区别与分类问题，需要预测的是一个任意实数，最常使用的损失函数是均方误差 MSE,定义如下：</p>
<p>$$MSE(y,y’)&#x3D;\frac{\sum_{i&#x3D;1}^n(y_i-y_i’)^2}{n}$$</p>
<h3 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h3><p>反向传播算法是训练神经网络的核心算法，它可以根据定义好的损失函数优化神经网络的参数值，是神经网络模型的损失函数达到一个较小的值。</p>
<p>梯度下降算法是最常用的神经网络优化方法，假设用 θ 表示神经网络的参数， J(θ) 表示给定参数下的取值，梯度下降算法会迭代式的更新 θ，让迭代朝着损失最小的方向更新。梯度通过求偏导的方式计算，梯度为 $$\frac{∂}{∂θ}J(θ)$$ 然后定义一个学习率 η。参数更新公式如下：$$θ_{n+1}&#x3D;θ_n-η\frac{∂}{∂θ_n}J(θ_n)$$</p>
<p>优化过程分为两步：</p>
<ol>
<li>通过向前传播算法得到预测值，将预测值与真实值之间对比差距。</li>
<li>通过反向传播算法计算损失函数对每一个参数的梯度，根据梯度和学习率是梯度下降算法更新每一个参数。</li>
</ol>
<p>为了降低计算量和加速训练过程，可以使用随机梯度下降算法，选取一部分数据进行训练。</p>
<p>学习率的设置可以通过指数衰减法，逐步减小学习率，可以在开始时快速得到一个较优解，然后减小学习率，使后模型的训练更加稳定。tf 提供了<code>tf.train.exponential_decay</code> 函数实现指数衰减学习率， <code>每一轮优化的学习率 = 初始学习率 * 衰减系数 ^ (学习步数 / 衰减速度)</code></p>
<h3 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h3><p>通过损失函数优化模型参数的时候，并不是让模型尽量的模拟训练数据的行为，而是通过训练数据对未知数据给出判断，当一个模型能完美契合训练数据的时候，损失函数为0，但是无法对未知数据做出可靠的判断，这就是过拟合。</p>
<p>避免过拟合的常用方法是正则化，就是在损失函数中加入刻画模型复杂度的指标，我们对模型的优化则变为 $$J(θ)+λR(w)$$ 其中 <code>R(w)</code> 刻画的是模型的复杂程度，λ 表示模型复杂损失在总损失中的比例。下面是常用的两种正则化函数：</p>
<p>L1正则化：会让参数变得稀疏，公式不可导</p>
<p>$$R(w) &#x3D; \Vert<del>w</del>\Vert_1 &#x3D; \sum_i|w_i|$$</p>
<p>L2正则化：不会让参数变得稀疏，公式可导</p>
<p>$$R(w) &#x3D; \Vert<del>w</del>\Vert_2^2 &#x3D; \sum_i|w_i^2|$$</p>
<p>在实际使用中会将 L1 正则化和 L2 正则化同时使用：</p>
<p>$$R(w) &#x3D; \sum_iα|w_i|+(1-α)w_i^2$$</p>
<h3 id="滑动平均模型"><a href="#滑动平均模型" class="headerlink" title="滑动平均模型"></a>滑动平均模型</h3><p>在采用随机梯度下降算法训练神经网络时，使用平均滑动模型可以在大部分情况下提高模型在测试数据上的表现。在 tf 中提供了 <code>tf.train.ExponentialMovingAverage</code> 来实现这个模型，通过设置一个衰减率来初始化，在其中维护一个影子变量，可以控制模型的更新速度。<br><code>影子变量值 = 衰减率 * 影子变量值 + (1 - 衰减率) * 待更新变量</code>，为了让模型前期更新比较快，还提供了 num_updates 参数，每次使用的衰减率为：</p>
<p>$$min(decay,\frac{1+numupdates}{10+numupdates})$$</p>
<hr>
<p>附 mathjax 语法教程：<a target="_blank" rel="noopener" href="http://blog.csdn.net/u010945683/article/details/46757757">http://blog.csdn.net/u010945683/article/details/46757757</a></p>
<p>本章结束～</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/09/21/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/09/21/1.html" class="post-title-link" itemprop="url">深度学习系列第一篇 — 入门</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-09-21 00:00:00" itemprop="dateCreated datePublished" datetime="2017-09-21T00:00:00+00:00">2017-09-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>这篇文章是学习人工智能的笔记，首先抛出下面一个问题。</p>
<h4 id="人工智能、机器学习和深度学习之间的关系？"><a href="#人工智能、机器学习和深度学习之间的关系？" class="headerlink" title="人工智能、机器学习和深度学习之间的关系？"></a>人工智能、机器学习和深度学习之间的关系？</h4><p><img src="/resource/img/deep_learning/relation.jpg" alt="三者之间的联系"></p>
<p>从图中可以看出人工智能概念的范围更广，机器学习是其中的一个子集，而深度学习又是机器学习中的一个子集。</p>
<p>深度学习的应用领域在计算机视觉、语音识别、自然语言处理和人机博弈方面比基于数理统计的机器学习会有更高的准确度。这里主要是做深度学习方面的学习笔记。</p>
<h2 id="深度学习的发展历程"><a href="#深度学习的发展历程" class="headerlink" title="深度学习的发展历程"></a>深度学习的发展历程</h2><p>深度发学习是深度神经网络的代名词，其起源于上世纪，只是在这几年开始火起来。</p>
<p>早期的神经网络模型类似于放生机器学习，由人类大脑的神经元演化出的神经元模型，见下图（图摘自《TensorFlow 实战Google深度学习框架》）：<br><img src="/resource/img/deep_learning/neuron.jpg" alt="对比图"></p>
<p>后面出现了感知机模型、分布式知识表达和神经网络反向传播算法，再到后来的卷积神经网络、循环神经网络和 LSTM 模型。</p>
<p>在神经网络发展的同时，传统机器学习算法的研究也在不断发展，上世纪 90 年代末逐步超越了神经网络，在当时相比之下传统机器学习算法有更好的识别准确率，而神经网络由于数据量和计算能力的限制发展比较困难。到了最近几年，由于云计算、GPU、大数据等的出现，为神经网络的发展做好了铺垫，AI 开始了一个新的时代。从自身出发，高中设立的一个比较模糊的梦想是参与到人工智能的研发当中去，所以大学学了计算机，当梦想与时代的发展有了一个交点，梦想的实现变得更加触手可及。</p>
<p>下面一张图表是对比主流深度学习开源工具（图摘自《TensorFlow 实战Google深度学习框架》）<br><img src="/resource/img/deep_learning/deeplearning_1.jpg" alt="d1"><br><img src="/resource/img/deep_learning/deeplearning_2.jpg" alt="d2"></p>
<p>目前我听说的比较多的两个开源工具是 Caffe 和 TensorFlow，然后去看了下 Github 关注量，前者 20.1k 后者 69.3k，TensorFlow 应该是目前最火的一个深度学习框架了吧。这篇文章包括后面的文章都会去记录 TensorFlow 的学习过程，下面的内容是介绍 TensorFlow 的基础概念，介绍中我尽量避免加入代码，因为目前 TensorFlow 更新比较快，发现好多写法在新的版本中不再被支持。</p>
<h2 id="TensorFlow-学起来"><a href="#TensorFlow-学起来" class="headerlink" title="TensorFlow 学起来"></a>TensorFlow 学起来</h2><p>TensorFlow 有两个重要概念 Tensor （张量）和 Flow（流），Tensor 表名的是数据结构，Flow 提现的是计算模型。</p>
<p><strong>PS:以下将 TensorFlow 简称为 tf</strong></p>
<h3 id="tf-计算模型-—-计算图"><a href="#tf-计算模型-—-计算图" class="headerlink" title="tf 计算模型 — 计算图"></a>tf 计算模型 — 计算图</h3><p>tf 通过计算图来表述计算的编程系统，其中的每个节点表示一个计算，不同点之间的连接表达依赖关系。下面几行代码表达一下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">a = tf.constant([1.0, 2.0], name=&#x27;a&#x27;)</span><br><span class="line">b = tf.constant([2.0, 3.0], name=&#x27;b&#x27;)</span><br><span class="line">result = a + b</span><br></pre></td></tr></table></figure>

<p>上面的代码在计算图中会有 a、b、a + b三个节点。tf 默认会有一个全局的计算图，也可以生成新的计算图，<strong>不同计算图之间不会共享张量和运算</strong>。</p>
<p>计算图中可以通过<strong>集合</strong>的方式管理不同的资源，这些资源可以是张量、变量或者队列资源等。</p>
<h3 id="tf-数据模型-—-张量"><a href="#tf-数据模型-—-张量" class="headerlink" title="tf 数据模型 — 张量"></a>tf 数据模型 — 张量</h3><p>张量是 tf 管理和表示数据的形式，可以简单理解为多维数组。零阶张量表示标量，就是一个数；一阶张量是一个一维数组；n 阶张量是一个 n 维数组。 <code>tf.add(a, b, name=&#39;add&#39;)</code> 这行代码在运行时并不会得到结果，而是一个结果的引用，是一个张量的结构，包含三个属性 name、shape、dtype，name 仅仅是一个节点的名称；shape 是张量的维度，这个是一维的，长度为 2，这个属性比较重要；dtype 是数据类型，每个张量有唯一的数据类型，不同张量之间的计算需要保证类型统一。</p>
<p>上面的例子就是对两个常量做加法，然后生成计算结果的引用。</p>
<h3 id="tf-运行模型-—-会话"><a href="#tf-运行模型-—-会话" class="headerlink" title="tf 运行模型 — 会话"></a>tf 运行模型 — 会话</h3><p>tf 的会话用来执行定义好的运算，会话用来管理运行过程中的所有资源，计算完成后会帮助回收资源，通过 <code>with tf.Session() as sess:</code> 这种方式会在 with 结束时自动关闭回收资源。</p>
<p>通过 <code>tf.ConfigProto</code> 可以配置类似并行线程数、GPU分配策略、运算超时时间等参数，将配置添加到 <code>tf.Session</code> 中创建会话。</p>
<h3 id="向前传播算法"><a href="#向前传播算法" class="headerlink" title="向前传播算法"></a>向前传播算法</h3><p>通过全连接网络结构介绍，一个神经元有多个输入和一个输出，输出是不同输入的加权和，不同的输入权重就是神经网络的参数，神经网络的优化就是优化参数取值的过程。全连接网络结构是指相邻两层之间任意两个节点之间都有连接。</p>
<p>向前传播算法需要的三部分信息：</p>
<ul>
<li>第一部分从实体中取出特征向量作为输入。</li>
<li>第二部分是神经网络的连接结构，不同神经元之间的输入输出的连接关系。</li>
<li>第三部分是每个神经元中的参数。</li>
</ul>
<p>在 tf 中通过变量（<code>tf.Variable</code>）来保存和更新神经网络中的参数。</p>
<p><img src="/resource/img/deep_learning/xiangqianchuanbo.png" alt="xiangqianchuanbo"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># w1 是第一层，通过随机数生成一个 （2,3） 的矩阵</span></span><br><span class="line">w1 = tf.Variable(tf.random_normal([<span class="number">2</span>, <span class="number">3</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># w2 是第二层，通过随机石生成一个 （3,1） 的矩阵</span></span><br><span class="line">w2 = tf.Variable(tf.random_normal([<span class="number">3</span>, <span class="number">1</span>], stddev=<span class="number">1</span>, seed=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># x 是输入层，为一个 （1,2） 的矩阵</span></span><br><span class="line">x = tf.placeholder(tf.float32, shape=(<span class="number">1</span>, <span class="number">2</span>), name=<span class="string">&#x27;input&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过 tensorflow 提供的矩阵相乘算法计算</span></span><br><span class="line">a = tf.matmul(x, w1)</span><br><span class="line">y = tf.matmul(a, w2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 这里初始化所有变量</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># 通过 输入值 x 与 第一层的参数进行矩阵相乘，再与 第二层的参数进行矩阵相乘，实现神经网络的向前传播算法。</span></span><br><span class="line">    <span class="built_in">print</span> sess.run(y, feed_dict=&#123;x: [[<span class="number">0.7</span>, <span class="number">0.9</span>]]&#125;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[[ 3.95757794]]
</code></pre>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/08/17/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/08/17/1.html" class="post-title-link" itemprop="url">AlfredWorkflow</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-08-17 00:00:00" itemprop="dateCreated datePublished" datetime="2017-08-17T00:00:00+00:00">2017-08-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>开发工程师常用工具箱</p>
<h2 id="全局预览"><a href="#全局预览" class="headerlink" title="全局预览"></a>全局预览</h2><p><img src="/resource/img/Jietu20170817-204623.jpg" alt="1"></p>
<h2 id="支持的命令"><a href="#支持的命令" class="headerlink" title="支持的命令"></a>支持的命令</h2><p><img src="/resource/img/Jietu20170817-204906.jpg" alt="2"></p>
<ul>
<li><code>ntime</code> 时间戳转换，支持标准时间格式与时间戳自动检测转换，回车复制结果到剪贴板</li>
<li><code>nb64d</code> Base64 解码</li>
<li><code>nb64e</code> Base64 编码</li>
<li><code>nmd5</code> MD5 生成</li>
<li><code>ncny</code> 数字转人民币大写</li>
<li><code>nu2c</code> Unicode 码转中文</li>
<li><code>nc2u</code> 中文转 Unicode 码</li>
<li><code>nip</code> IP 地址查询</li>
<li><code>nrdm</code> 随机字符串生成，输入长度</li>
<li><code>nhelp</code> 列出所有支持的命令</li>
</ul>
<h4 id="欢迎大家补充。"><a href="#欢迎大家补充。" class="headerlink" title="欢迎大家补充。"></a>欢迎大家补充。</h4><h2 id="个人博客"><a href="#个人博客" class="headerlink" title="个人博客"></a>个人博客</h2><p><a target="_blank" rel="noopener" href="http://noogel.xyz/">知一的指纹</a></p>
<h2 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h2><p><a target="_blank" rel="noopener" href="https://github.com/noogel/Alfred-Workflow">Noogel’s github Alfred-Workflow</a></p>
<blockquote>
<p>Update at 2017-08-17</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/06/24/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/06/24/1.html" class="post-title-link" itemprop="url">Python字符串编码</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-06-24 00:00:00" itemprop="dateCreated datePublished" datetime="2017-06-24T00:00:00+00:00">2017-06-24</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>说道Python字符串编码处理会让很人头疼，下面介绍一些 Python 处理字符串编码的方式。</p>
<h2 id="chardet-模块"><a href="#chardet-模块" class="headerlink" title="chardet 模块"></a>chardet 模块</h2><p>chardet 主要用于编码识别</p>
<p>pip安装： <code>sudo pip install chardet</code></p>
<p>官方地址： <a target="_blank" rel="noopener" href="http://pypi.python.org/pypi/chardet">http://pypi.python.org/pypi/chardet</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [1]: import chardet</span><br><span class="line"></span><br><span class="line">In [2]: import urllib</span><br><span class="line"></span><br><span class="line">In [3]: test_data = urllib.urlopen(&#x27;http://www.baidu.com/&#x27;).read()</span><br><span class="line"></span><br><span class="line">In [4]: chardet.detect(test_data)</span><br><span class="line">Out[4]: &#123;&#x27;confidence&#x27;: 0.99, &#x27;language&#x27;: &#x27;&#x27;, &#x27;encoding&#x27;: &#x27;utf-8&#x27;&#125;</span><br><span class="line"></span><br><span class="line">In [5]: isinstance(test_data.decode(&#x27;utf-8&#x27;), unicode)</span><br><span class="line">Out[5]: True</span><br><span class="line"></span><br><span class="line">In [6]: isinstance(test_data, unicode)</span><br><span class="line">Out[6]: False</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行结果：<br><code>&#123;&#39;confidence&#39;: 0.99, &#39;language&#39;: &#39;&#39;, &#39;encoding&#39;: &#39;utf-8&#39;&#125;</code><br>运行结果表示有 99% 的概率认为这段代码是 utf-8 编码方式。</p>
<p>对于大文件的编码识别，可以通过 UniversalDetector 部分读取进行检查。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">In [1]: import urllib</span><br><span class="line"></span><br><span class="line">In [2]: import chardet</span><br><span class="line"></span><br><span class="line">In [3]: from chardet.universaldetector import UniversalDetector</span><br><span class="line"></span><br><span class="line">In [4]: uso = urllib.urlopen(&#x27;http://www.baidu.com/&#x27;)</span><br><span class="line">   ...: det = UniversalDetector()</span><br><span class="line">   ...: for line in uso.readlines():</span><br><span class="line">   ...:     det.feed(line)</span><br><span class="line">   ...:     if det.done:</span><br><span class="line">   ...:         break</span><br><span class="line">   ...: det.close()</span><br><span class="line">   ...: uso.close()</span><br><span class="line">   ...: det.result</span><br><span class="line">   ...:</span><br><span class="line">Out[4]: &#123;&#x27;confidence&#x27;: 0.99, &#x27;encoding&#x27;: &#x27;utf-8&#x27;, &#x27;language&#x27;: &#x27;&#x27;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>运行结果：<br><code>&#123;&#39;confidence&#39;: 0.99, &#39;encoding&#39;: &#39;utf-8&#39;, &#39;language&#39;: &#39;&#39;&#125;</code></p>
<h2 id="Python-模块之-codecs"><a href="#Python-模块之-codecs" class="headerlink" title="Python 模块之 codecs"></a>Python 模块之 codecs</h2><blockquote>
<p>Mark未完</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/06/17/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/06/17/1.html" class="post-title-link" itemprop="url">你的Ubuntu还可以这么美</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-06-17 00:00:00" itemprop="dateCreated datePublished" datetime="2017-06-17T00:00:00+00:00">2017-06-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>先上两张桌面和开发环境见下图<br><img src="/resource/img/Ubuntu/full-screen.png" alt="桌面"><br><img src="/resource/img/Ubuntu/full-dev.png" alt="开发环境"></p>
<h2 id="系统优化"><a href="#系统优化" class="headerlink" title="系统优化"></a>系统优化</h2><h3 id="更新源"><a href="#更新源" class="headerlink" title="更新源"></a>更新源</h3><p>更新前先设置源为<code>aliyun</code>的，国内访问速度快。</p>
<p><img src="/resource/img/Ubuntu/sys-up.png" alt="更新源"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br></pre></td></tr></table></figure>

<h3 id="删除Amazon的链接"><a href="#删除Amazon的链接" class="headerlink" title="删除Amazon的链接"></a>删除Amazon的链接</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove unity-webapps-common</span><br></pre></td></tr></table></figure>

<h3 id="主题美化"><a href="#主题美化" class="headerlink" title="主题美化"></a>主题美化</h3><p>先装 Unity 图形管理工具<br><img src="/resource/img/Ubuntu/unity.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install unity-tweak-tool</span><br></pre></td></tr></table></figure>

<p>然后安装 Flatabulous 主题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:noobslab/themes</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install flatabulous-theme</span><br></pre></td></tr></table></figure>

<p>和配套图标</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:noobslab/icons</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install ultra-flat-icons</span><br></pre></td></tr></table></figure>

<p>更换操作如下图：</p>
<p><img src="/resource/img/Ubuntu/unity-them.png"><br><img src="/resource/img/Ubuntu/unity-font.png"></p>
<p>至此主题美化完成</p>
<h3 id="System-Load-Indicator（系统状态指示器）"><a href="#System-Load-Indicator（系统状态指示器）" class="headerlink" title="System Load Indicator（系统状态指示器）"></a>System Load Indicator（系统状态指示器）</h3><p><img src="/resource/img/Ubuntu/sys-m.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository ppa:indicator-multiload/stable-daily</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install indicator-multiload</span><br></pre></td></tr></table></figure>

<h3 id="微软雅黑"><a href="#微软雅黑" class="headerlink" title="微软雅黑"></a>微软雅黑</h3><p><a target="_blank" rel="noopener" href="http://www.mycode.net.cn/wp-content/uploads/2015/07/YaHeiConsolas.tar.gz">字体下载</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf YaHeiConsolas.tar.gz</span><br><span class="line">sudo mv YaHeiConsolas.ttf /usr/share/fonts</span><br><span class="line">sudo chmod 755 /usr/share/fonts/YaHeiConsolas.ttf</span><br></pre></td></tr></table></figure>


<h3 id="安装zsh"><a href="#安装zsh" class="headerlink" title="安装zsh"></a>安装zsh</h3><p><img src="/resource/img/Ubuntu/zsh.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zsh</span><br><span class="line">zsh --version</span><br><span class="line">sudo chsh -s $(which zsh)</span><br></pre></td></tr></table></figure>
<p>然后再重新注销登录就好了</p>
<h2 id="必装软件"><a href="#必装软件" class="headerlink" title="必装软件"></a>必装软件</h2><blockquote>
<p>下面介绍的软件有一部分是通过 deb 文件安装的，具体安装方式见 系统使用技巧。</p>
</blockquote>
<h3 id="系统软件"><a href="#系统软件" class="headerlink" title="系统软件"></a>系统软件</h3><ul>
<li>浏览器： Chrome</li>
<li>搜狗输入法： sougoupinyin</li>
<li>为知笔记： wiznote</li>
<li>系统状态指示器： System Load Indicator</li>
<li>SS你懂得： Shadowsocks-Qt5</li>
<li>Unity图形管理工具： unity tweak tool</li>
<li>图片编辑工具： gimp</li>
<li>思维导图： xmind</li>
<li>EPUB文件编辑： sigil</li>
<li>Linux下的Dash： zeal</li>
<li>Linux下Albert： albert</li>
<li>网易云音乐播放器</li>
<li>Robomongo</li>
</ul>
<h3 id="数据库及工具"><a href="#数据库及工具" class="headerlink" title="数据库及工具"></a>数据库及工具</h3><ul>
<li>mysql</li>
<li>mongodb</li>
<li>redis</li>
<li>MySQL Workbench</li>
</ul>
<h3 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h3><ul>
<li>Python IDE： Pycharm</li>
</ul>
<h3 id="命令行工具"><a href="#命令行工具" class="headerlink" title="命令行工具"></a>命令行工具</h3><ul>
<li>zsh</li>
<li>oh-my-zsh</li>
<li>vim</li>
<li>git</li>
</ul>
<h2 id="系统使用技巧"><a href="#系统使用技巧" class="headerlink" title="系统使用技巧"></a>系统使用技巧</h2><h3 id="DEB软件安装"><a href="#DEB软件安装" class="headerlink" title="DEB软件安装"></a>DEB软件安装</h3><ul>
<li>安装命令</li>
</ul>
<p><code>sudo dpkg -i xxx.deb</code></p>
<ul>
<li>安装过程中可能会报缺少依赖的错，执行下面命令自动安装依赖</li>
</ul>
<p><code>sudo apt-get install -f</code></p>
<ul>
<li>再次执行安装命令</li>
</ul>
<p><code>sudo dpkg -i xxx.deb</code></p>
<h3 id="卸载不再依赖的包-命令"><a href="#卸载不再依赖的包-命令" class="headerlink" title="卸载不再依赖的包 命令"></a>卸载不再依赖的包 命令</h3><p><code>sudo apt-get autoremove</code></p>
<blockquote>
<p>未完待续，欢迎大家发送你的优化点到我的邮箱 <a href="mailto:&#x6e;&#x6f;&#x6f;&#x67;&#x65;&#x6c;&#64;&#49;&#54;&#x33;&#46;&#99;&#x6f;&#109;">&#x6e;&#x6f;&#x6f;&#x67;&#x65;&#x6c;&#64;&#49;&#54;&#x33;&#46;&#99;&#x6f;&#109;</a></p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/05/06/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/05/06/1.html" class="post-title-link" itemprop="url">Windows 效率工具包</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-05-06 00:00:00" itemprop="dateCreated datePublished" datetime="2017-05-06T00:00:00+00:00">2017-05-06</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>管理工具：Vstart 5.1</p>
<p>截图工具：FastStone Capture</p>
<p>定时关机：Easy定时关机</p>
<p>文本比较工具：Beyond Compare</p>
<p>FTP工具：FlashFXP</p>
<p>源代码格式：CoolFormat</p>
<p>SSH客户端：SecureCRT putty</p>
<p>文件搜索工具：Everything</p>
<p>翻译软件：QTranslate</p>
<p>局域网聊天:飞鸽传书</p>
<p>剪贴板增强：Ditto</p>
<p>数据恢复软件：Recover My Files</p>
<p>虚拟光驱：UltraISO</p>
<p>GIF录屏软件：licecap</p>
<p>PDF文件编辑工具：PDFEditor</p>
<p>音视频转换软件：FormatFactory</p>
<p>二维码生成软件：Psytec QR Code Editor</p>
<p>IP查询转换工具：纯真IP</p>
<p>破解软件：EWSA</p>
<p>OllyICE</p>
<p>VNCViewer</p>
<p>JAVA反编译：jd-gui</p>
<p>Android逆向助手</p>
<p>磁盘剩余空间查询：SpaceSniffer</p>
<p>键位映射工具：KeySwap</p>
<p>键盘测试工具：Keyboard Test Utility</p>
<p>GHO镜像浏览</p>
<p>磁盘分区软件：DiskGenius</p>
<p>系统镜像制作：老毛桃、晨枫U盘启动</p>
<p>BCD文件编辑：EasyBCD</p>
<p>win7激活软件、HEU_KMS_Activator</p>
<p>科学上网：ShadowsocksR</p>
<p>Spy4Win</p>
<p>任务管理器增强：System Explorer</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/03/15/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/15/1.html" class="post-title-link" itemprop="url">关于Java的最初了解</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-15 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-15T00:00:00+00:00">2017-03-15</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Apache-Maven"><a href="#Apache-Maven" class="headerlink" title="Apache Maven"></a>Apache Maven</h2><p>Maven 是一个项目管理和构建自动化工具。但是对于我们程序员来说，我们最关心的是它的项目构建功能，它可以规定项目的文件结构，比如下面：</p>
<table>
<thead>
<tr>
<th>目录</th>
<th>目的</th>
</tr>
</thead>
<tbody><tr>
<td>${basedir}</td>
<td>存放 pom.xml和所有的子目录</td>
</tr>
<tr>
<td>${basedir}&#x2F;src&#x2F;main&#x2F;java</td>
<td>项目的 java源代码</td>
</tr>
<tr>
<td>${basedir}&#x2F;src&#x2F;main&#x2F;resources</td>
<td>项目的资源，比如说 property文件</td>
</tr>
<tr>
<td>${basedir}&#x2F;src&#x2F;test&#x2F;java</td>
<td>项目的测试类，比如说 JUnit代码</td>
</tr>
<tr>
<td>${basedir}&#x2F;src&#x2F;test&#x2F;resources</td>
<td>测试使用的资源</td>
</tr>
</tbody></table>
<h2 id="Spring-Boot"><a href="#Spring-Boot" class="headerlink" title="Spring Boot"></a>Spring Boot</h2><p>Spring Boot 是一个轻量级框架，Spring Boot 的目的是提供一组工具，以便快速构建容易配置的 Spring 应用程序。</p>
<h2 id="Apache-Tomcat"><a href="#Apache-Tomcat" class="headerlink" title="Apache Tomcat"></a>Apache Tomcat</h2><p>Tomcat是由Apache软件基金会下属的Jakarta项目开发的一个Servlet容器，实现了对Servlet和JavaServer Page（JSP）的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全域管理和Tomcat阀等。由于Tomcat本身也内含了一个HTTP服务器，它也可以被视作一个单独的Web服务器。Apache Tomcat包含了一个配置管理工具，也可以通过编辑XML格式的配置文件来进行配置。</p>
<h2 id="Hibernate"><a href="#Hibernate" class="headerlink" title="Hibernate"></a>Hibernate</h2><p>是一种Java语言下的对象关系映射解决方案。Hibernate不仅负责从Java类到数据库表的映射（还包括从Java数据类型到SQL数据类型的映射），还提供了面向对象的数据查询检索机制，从而极大地缩短了手动处理SQL和JDBC上的开发时间。</p>
<h2 id="Spring-web-MVC"><a href="#Spring-web-MVC" class="headerlink" title="Spring web MVC"></a>Spring web MVC</h2><p>框架提供了模型-视图-控制的体系结构和可以用来开发灵活、松散耦合的 web 应用程序的组件。MVC 模式导致了应用程序的不同方面(输入逻辑、业务逻辑和 UI 逻辑)的分离，同时提供了在这些元素之间的松散耦合。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/03/02/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/03/02/1.html" class="post-title-link" itemprop="url">结算开发中遇到的坑</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-03-02 00:00:00" itemprop="dateCreated datePublished" datetime="2017-03-02T00:00:00+00:00">2017-03-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>坑1：浮点数不精确性</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [1]: 0.1+0.1+0.1-0.3</span><br><span class="line">Out[1]: 5.551115123125783e-17</span><br></pre></td></tr></table></figure>
<p>解决办法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [2]: from decimal import Decimal</span><br><span class="line">In [3]: Decimal(&#x27;0.1&#x27;) + Decimal(&#x27;0.1&#x27;) + Decimal(&#x27;0.1&#x27;) - Decimal(&#x27;0.3&#x27;)</span><br><span class="line">Out[3]: Decimal(&#x27;0.0&#x27;)</span><br></pre></td></tr></table></figure>
<p>坑2：Decimal使用问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [5]: Decimal(0.1) + Decimal(0.1) + Decimal(0.1) - Decimal(0.3)</span><br><span class="line">Out[5]: Decimal(&#x27;2.775557561565156540423631668E-17&#x27;)</span><br></pre></td></tr></table></figure>
<p>解决办法：<br>参照坑1的解决办法，Decimal传入值需要str类型<br>更多用法查看：<a target="_blank" rel="noopener" href="https://docs.python.org/2/library/decimal.html">https://docs.python.org/2/library/decimal.html</a></p>
<p>坑3：四舍五入不准确问题</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [3]: &#x27;&#123;:.2f&#125;&#x27;.format(Decimal(str(1001.8250)))</span><br><span class="line">Out[3]: &#x27;1001.82&#x27;</span><br><span class="line">In [2]: Decimal(&#x27;1001.8250&#x27;).quantize(Decimal(&#x27;0.01&#x27;))</span><br><span class="line">Out[2]: Decimal(&#x27;1001.82&#x27;)</span><br><span class="line">In [4]: round(2.55, 1)</span><br><span class="line">Out[4]: 2.5</span><br></pre></td></tr></table></figure>
<p>解决办法：<br>发现问题原因为在不能正确四舍五入的float数值中都是因为数据存储末位的.5被存储为.4999999…的形式，解决办法是在.5上加.1的值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def exact_round(num, exp=2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    准确的四舍五入方法</span><br><span class="line">    :param num: 数值</span><br><span class="line">    :param exp: 保留精度</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    str_num = str(num)</span><br><span class="line">    dec_num = Decimal(str_num)</span><br><span class="line">    exp_unit = Decimal(&#x27;0.1&#x27;) ** exp</span><br><span class="line">    mini_unit = Decimal(&#x27;0.1&#x27;) ** (exp + 1)</span><br><span class="line">    if dec_num % exp_unit == (5 * mini_unit):</span><br><span class="line">        dec_num += mini_unit</span><br><span class="line">    return Decimal(dec_num).quantize(exp_unit, rounding=ROUND_HALF_EVEN)</span><br></pre></td></tr></table></figure>

<p>为了验证这个方法写了个测试脚本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">摘    要: exact_round.py</span><br><span class="line">创 建 者: abc</span><br><span class="line">创建日期: 2017-01-05</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">__author__ = &quot;abc&quot;</span><br><span class="line"></span><br><span class="line">from decimal import Decimal, ROUND_HALF_EVEN</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def exact_round(num, exp=2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    准确的四舍五入方法</span><br><span class="line">    :param num: 数值</span><br><span class="line">    :param exp: 保留精度</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    str_num = str(num)</span><br><span class="line">    dec_num = Decimal(str_num)</span><br><span class="line">    exp_unit = Decimal(&#x27;0.1&#x27;) ** exp</span><br><span class="line">    mini_unit = Decimal(&#x27;0.1&#x27;) ** (exp + 1)</span><br><span class="line">    raw_num = dec_num</span><br><span class="line">    if dec_num % exp_unit == (5 * mini_unit):</span><br><span class="line">        dec_num += mini_unit</span><br><span class="line">    raw_result = Decimal(raw_num).quantize(exp_unit, rounding=ROUND_HALF_EVEN)</span><br><span class="line">    result = Decimal(dec_num).quantize(exp_unit, rounding=ROUND_HALF_EVEN)</span><br><span class="line">    if result != raw_result:</span><br><span class="line">        print &quot;raw:round(&#123;&#125;, &#123;&#125;) = &gt; &#123;&#125;; fixed: round(&#123;&#125;, &#123;&#125;) =&gt; &#123;&#125;&quot;.format(</span><br><span class="line">            raw_num, exp, raw_result,</span><br><span class="line">            dec_num, exp, result</span><br><span class="line">        )</span><br><span class="line">    return result</span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    val = 900.0000</span><br><span class="line">    while val &lt; 1001.8600:</span><br><span class="line">        for exp in range(0, 6):</span><br><span class="line">            exact_round(val, exp=exp)</span><br><span class="line">        val += 0.0005</span><br></pre></td></tr></table></figure>
<p>脚本中我们将被修正过的数据打印出来，发现被打印出来的都是四舍五入不正确的数值，经过方法处理可以保证准确的输出。</p>
<p>因为我们的测试只是覆盖了部分的数值，精度深度也只到到了6位，也不能保证说方法没有问题。<br>后来询问了在银行做开发的朋友，他们对于数据的计算都是在数据库的存储过程中运算的，并对上面坑中的数值放到数据库中做四舍五入发现确实没有问题。</p>
<p>于是我将这个方法做的运算与数据库的运算结果做对比写了测试脚本。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/python</span><br><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">摘    要: test_db_round.py</span><br><span class="line">创 建 者: abc</span><br><span class="line">创建日期: 2017-01-06</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">__author__ = &quot;abc&quot;</span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line"></span><br><span class="line">sys.path.append(os.path.dirname(os.path.split(os.path.realpath(__file__))[0]))</span><br><span class="line"></span><br><span class="line">from lib.utils import exact_round</span><br><span class="line">from model import Model</span><br><span class="line"> </span><br><span class="line">def test_db_round(val, exp):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    test_db_round</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    sql = &quot;SELECT round(&#123;&#125;, &#123;&#125;) as val&quot;.format(str(val), exp)</span><br><span class="line">    db_round = Model().raw(sql)[0][&quot;val&quot;]</span><br><span class="line">    exa_round = exact_round(val, exp)</span><br><span class="line">    if str(db_round) != str(exa_round):</span><br><span class="line">        print &quot;db:&#123;&#125;; ex:&#123;&#125;&quot;.format(str(db_round), str(exa_round))</span><br><span class="line"> </span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    val = 900.0000</span><br><span class="line">    while val &lt; 1001.8600:</span><br><span class="line">        for exp in range(0, 6):</span><br><span class="line">            test_db_round(val, exp=exp)</span><br><span class="line">        val += 0.0005</span><br></pre></td></tr></table></figure>
<p>经过测试后发现没有数据被打印出，证明在测试范围内Python方法和数据库的运算结果没有差异。</p>
<p>关于浮点数不精确性的事情相信学过计算机组成原理这门课程的都明白，这里不再赘述，放个链接：<br><a target="_blank" rel="noopener" href="http://www.cnblogs.com/kubixuesheng/p/4107309.html">从如何判断浮点数是否等于0说起——浮点数的机器级表示</a></p>
<p>话说为什么要在Python中做财务相关运算呢，可能最初开发这个系统的人缺乏这方面的经验，然后通过扩展精度保留位数来解决这个问题的，但终究在做四舍五入时可能产生1分的差异。<br>既然发现这个问题，本着眼里不揉沙子的态度，快速的解决方案是在Python中替换原来的四舍五入函数，长期策略是逐步将计算过程挪到数据库通过存储过程来实现。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://noge.top/2017/02/09/1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="nuniok">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="码力欧">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2017/02/09/1.html" class="post-title-link" itemprop="url">Tensorflow学习</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-02-09 00:00:00" itemprop="dateCreated datePublished" datetime="2017-02-09T00:00:00+00:00">2017-02-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子1</span></span><br><span class="line"></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>).astype(np.float32)</span><br><span class="line">y_data = x_data*<span class="number">0.4</span> + <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">weight = tf.Variable(tf.random_uniform([<span class="number">1</span>], -<span class="number">0.1</span>, <span class="number">1.0</span>))</span><br><span class="line">biases = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">y = weight * x_data + biases</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line"><span class="comment"># 误差传递方法是梯度下降法</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"><span class="comment"># 始化所有之前定义的Variable</span></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span> step, sess.run(weight), sess.run(biases)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:From &lt;ipython-input-3-3c832ce985bb&gt;:16 in &lt;module&gt;.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
0 [ 0.8605063] [ 0.92711782]
20 [ 0.49690402] [ 0.8437199]
40 [ 0.42823532] [ 0.88360143]
60 [ 0.40822706] [ 0.89522189]
80 [ 0.40239716] [ 0.89860773]
100 [ 0.40069851] [ 0.89959431]
120 [ 0.40020356] [ 0.89988178]
140 [ 0.40005937] [ 0.89996552]
160 [ 0.40001735] [ 0.8999899]
180 [ 0.40000507] [ 0.89999706]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例子2</span></span><br><span class="line"></span><br><span class="line">matrix1 = tf.constant([[<span class="number">3</span>,<span class="number">3</span>]])</span><br><span class="line">matrix2 = tf.constant([[<span class="number">2</span>], [<span class="number">2</span>]])</span><br><span class="line"></span><br><span class="line">product = tf.matmul(matrix1, matrix2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 1</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">result = sess.run(product)</span><br><span class="line"><span class="built_in">print</span> result</span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 2</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result = sess.run(product)</span><br><span class="line">    <span class="built_in">print</span> result</span><br></pre></td></tr></table></figure>

<pre><code>[[12]]
[[12]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Variable变量</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">state = tf.Variable(<span class="number">0</span>, name=<span class="string">&#x27;counter&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义常量1</span></span><br><span class="line">one = tf.constant(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义加法步骤 (注: 此步并没有直接计算)</span></span><br><span class="line">new_value = tf.add(state, one)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 State 更新成 new_value</span></span><br><span class="line">update = tf.assign(state, new_value)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        sess.run(update)</span><br><span class="line">        <span class="built_in">print</span> sess.run(state)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:From &lt;ipython-input-12-816914535228&gt;:14 in &lt;module&gt;.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
1
2
3
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># placeholder 传入值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 预定义传入值</span></span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line">output = tf.mul(input1, input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># feed_dict传入实际值</span></span><br><span class="line">    <span class="built_in">print</span> sess.run(output, feed_dict=&#123;input1:[<span class="number">7.</span>], input2: [<span class="number">2.</span>]&#125;)</span><br></pre></td></tr></table></figure>

<pre><code>[ 14.]
</code></pre>
<h2 id="Activation-Functions-激励函数-tf-nn"><a href="#Activation-Functions-激励函数-tf-nn" class="headerlink" title="Activation Functions 激励函数 tf.nn"></a>Activation Functions 激励函数 tf.nn</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加神经层 add_layer</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add_layer</span>(<span class="params">inputs, in_size, out_size, activation_function=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># 在生成初始参数时，随机变量(normal distribution)会比全部为0要好很多</span></span><br><span class="line">    <span class="comment"># 所以我们这里的weights为一个in_size行, out_size列的随机变量矩阵。</span></span><br><span class="line">    weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    <span class="comment"># biases的推荐值不为0，所以我们这里是在0向量的基础上又加了0.1</span></span><br><span class="line">    biases = tf.Variable(tf.zeros([<span class="number">1</span>, out_size]) + <span class="number">0.1</span>)</span><br><span class="line">    wx_plus_b = tf.matmul(inputs, weights) + biases</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 建造神经网络</span></span><br><span class="line">x_data = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">300</span>)[:, np.newaxis]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方差0.05, x_data.shape数据形式</span></span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line"><span class="comment"># x_data 二次方</span></span><br><span class="line">y_data = np.square(x_data) - <span class="number">0.5</span> + noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入层 -&gt; 隐藏层 -&gt; 输出层</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入值</span></span><br><span class="line">xs = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># 定义隐藏层 1 输入层神经元数量， 输出层神经元数量，隐藏层神经元数量</span></span><br><span class="line">l1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line"><span class="comment"># 定义输出层</span></span><br><span class="line">prediction = add_layer(l1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测误差 二者差的平方和再求平均值</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提供学习效率0.1，通常小于1， 最小化误差</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 输出误差</span></span><br><span class="line">        <span class="built_in">print</span> sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:From &lt;ipython-input-36-245eb01b43f9&gt;:41 in &lt;module&gt;.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
0.295339
0.00607488
0.00473904
0.00429677
0.00412784
0.0040373
0.0039907
0.00395235
0.00391656
0.00388327
0.00385458
0.0038216
0.00378461
0.00374649
0.00369835
0.00366241
0.00363534
0.00361383
0.0035907
0.00357239
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">ax.scatter(x_data, y_data)</span><br><span class="line"><span class="comment"># plt.ion()</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/resource/img/tensorflow_study/output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示每一步的学习结果</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">        sess.run(train_step, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="comment"># 输出误差</span></span><br><span class="line">            <span class="comment"># print sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span></span><br><span class="line">            prediction_value = sess.run(prediction, feed_dict=&#123;xs: x_data&#125;)</span><br><span class="line">            fig = plt.figure()</span><br><span class="line">            ax = fig.add_subplot(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">            ax.scatter(x_data, y_data)</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="comment"># 去除原来的线</span></span><br><span class="line">                ax.lines.remove(lines[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">except</span>:</span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">            <span class="comment"># 画线</span></span><br><span class="line">            lines = ax.plot(x_data, prediction_value, <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line">            <span class="comment"># 暂停一个时间</span></span><br><span class="line">            plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/resource/img/tensorflow_study/output_8_0.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_1.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_2.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_3.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_4.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_5.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_6.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_7.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_8.png" alt="png"></p>
<p><img src="/resource/img/tensorflow_study/output_8_9.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Optimizer 优化器</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># GradientDescentOptimizer最基本的一种</span></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/6/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><a class="extend next" rel="next" href="/page/8/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2015 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">nuniok</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdn.jsdelivr.net/npm/mermaid@8.13.4/dist/mermaid.min.js","integrity":"sha256-96rwDGMWIQYB0yKGp1sKi1yrjrLPj2oT39IpbCsIrsg="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"nuniok","repo":"nuniok.github.io","client_id":"Ov23liWEs17fH5aYPIzS","client_secret":"6bbfa4b5a042d38b10c942b5c15f4d8a3895e982","admin_user":"nuniok","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"f96e384362e35929e7a2ca2c30b19531"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
